{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0232c872",
   "metadata": {},
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=35% align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77846170",
   "metadata": {},
   "source": [
    "# Building a Large Language Model from Scratch \u2014 A Step-by-Step Guide Using Python and PyTorch\n",
    "## Chapter 7 \u2014 Attention & Self-Attention Mechanism\n",
    "**\u00a9 Dr. Yves J. Hilpisch**<br>AI-Powered by GPT-5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58d442",
   "metadata": {},
   "source": [
    "## How to Use This Notebook\n",
    "\n",
    "- Implement scaled dot-product attention step by step before abstracting it away.\n",
    "- Inspect attention weights on curated toy sequences to build intuition.\n",
    "- Connect the math to code by tracing shapes and broadcasting rules carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73ad6d",
   "metadata": {},
   "source": [
    "### Roadmap\n",
    "\n",
    "We derive attention scores, apply masking, and then batch the operation so it scales to transformer blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2858b3c",
   "metadata": {},
   "source": [
    "### Study Tips\n",
    "\n",
    "Print intermediate tensors as you go. Seeing the score matrices and masks makes it easier to reason about what each line of code accomplishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure torch is available (Colab friendly)\n",
    "try:\n",
    "    import torch  # noqa\n",
    "    print('torch:', torch.__version__)\n",
    "except Exception:\n",
    "    import os\n",
    "    gpu = os.system('nvidia-smi > /dev/null 2>&1') == 0\n",
    "    index = (\n",
    "        'https://download.pytorch.org/whl/cu121'\n",
    "        if gpu else 'https://download.pytorch.org/whl/cpu'\n",
    "    )\n",
    "    get_ipython().run_line_magic('pip', f'install -q torch --index-url {index}')\n",
    "    import torch\n",
    "    print('torch:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ac315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%config InlineBackend.figure_format = 'svg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a671dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "def scaled_dot_product_attention(\n",
    "    q: Tensor,\n",
    "    k: Tensor,\n",
    "    v: Tensor,\n",
    "    mask: Tensor | None = None,\n",
    ") -> Tensor:\n",
    "    d = q.size(-1)\n",
    "    scores = (q @ k.transpose(-2, -1)) / (d ** 0.5)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    w = torch.softmax(scores, dim=-1)\n",
    "    return w @ v\n",
    "def causal_mask(batch: int, time: int, device=None):\n",
    "    base = torch.tril(torch.ones(time, time, device=device))\n",
    "    return base.unsqueeze(0).expand(batch, -1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f39e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shapes\n",
    "B, T, D = 1, 6, 4\n",
    "(B, T, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a toy input\n",
    "x = torch.randn(B, T, D)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32236ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a causal mask\n",
    "mask = causal_mask(B, T)\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8820239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply attention\n",
    "y = scaled_dot_product_attention(x, x, x, mask)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1121ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a row of attention weights\n",
    "with torch.no_grad():\n",
    "    d = x.size(-1)\n",
    "    scores = (x @ x.transpose(-2, -1)) / (d ** 0.5)\n",
    "    scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    w = torch.softmax(scores, dim=-1)[0]  # [T, T]\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.imshow(w, cmap='viridis', aspect='auto')\n",
    "plt.colorbar(label='weight')\n",
    "plt.xlabel('key\\npositions')\n",
    "plt.ylabel('query positions')\n",
    "plt.title('Causal attention weights (toy)')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d21080",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "- Implement additive attention and compare its behavior with scaled dot-product attention.\n",
    "- Visualize attention maps for sequences with padding to confirm masking works as expected.\n",
    "- Modify the notebook to support multi-head attention and measure the parameter count increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acded7d4",
   "metadata": {},
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=35% align=right>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}