{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Chapter 5 \u2014 PyTorch Essentials\n\n", "This notebook mirrors Chapter 5. It\u2019s self\u2011contained and can run on CPU, Apple MPS, or CUDA.\n", "If running on Google Colab, the first cell installs PyTorch."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["colab"]}, "outputs": [], "source": ["# Install PyTorch in Colab or when torch is missing.\n", "try:\n", "    import torch  # noqa:F401\n", "    print('torch:', torch.__version__)\n", "except Exception:\n", "    import os\n", "    gpu = os.system('nvidia-smi > /dev/null 2>&1') == 0\n", "    index = 'https://download.pytorch.org/whl/cu121' if gpu else 'https://download.pytorch.org/whl/cpu'\n", "    get_ipython().run_line_magic('pip', f'install -q torch --index-url {index}')\n", "    import torch\n", "    print('torch:', torch.__version__, 'cuda?', torch.cuda.is_available())\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Pick device\n", "import torch\n", "def pick_device():\n", "    if torch.cuda.is_available():\n", "        return torch.device('cuda')\n", "    mps = getattr(torch.backends, 'mps', None)\n", "    if mps and torch.backends.mps.is_available():\n", "        return torch.device('mps')\n", "    return torch.device('cpu')\n", "device = pick_device()\n", "device\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Tensors and Shapes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n", "y = torch.ones_like(x)\n", "x.shape, y.shape, x.device\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["b = torch.tensor([10.0, 20.0, 30.0])\n", "(x + b).shape, (x + b)[0]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = x.to(device)\n", "x.device\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Autograd in a Nutshell"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["w = torch.tensor([2.0, -3.0, 0.5], requires_grad=True)\n", "v = torch.tensor([1.0, 2.0, 3.0])\n", "loss = (w * v).sum()\n", "loss.backward()\n", "w.grad\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Optimizers and Parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = torch.nn.Linear(3, 1).to(device)\n", "opt = torch.optim.AdamW(model.parameters(), lr=3e-3)\n", "crit = torch.nn.MSELoss()\n", "type(model), type(opt), type(crit)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Training Loop Pattern"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# CPU generator for determinism\n", "g_cpu = torch.Generator().manual_seed(0)\n", "g_cpu\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create inputs X\n", "X = torch.randn(64, 3, generator=g_cpu).to(device)\n", "X\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Ground-truth weights\n", "true_w = torch.tensor([1.0, -2.0, 0.5], device=device)\n", "true_w\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Targets with a touch of noise\n", "y = (X @ true_w) + 0.1 * torch.randn(64, generator=g_cpu).to(device)\n", "y[:8]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Model, optimizer, loss\n", "model = torch.nn.Linear(3, 1).to(device)\n", "model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["opt = torch.optim.AdamW(model.parameters(), lr=5e-3)\n", "opt\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loss_fn = torch.nn.MSELoss()\n", "loss_fn\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train\n", "losses = []\n", "for step in range(201):\n", "    opt.zero_grad()\n", "    pred = model(X).squeeze(-1)\n", "    loss = loss_fn(pred, y)\n", "    loss.backward()\n", "    opt.step()\n", "    losses.append(loss.detach().item())\n", "    if step % 50 == 0:\n", "        print(step, round(losses[-1], 4))\n", "losses[-1]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "plt.style.use('seaborn-v0_8')\n", "%config InlineBackend.figure_format = 'svg'\n", "# Plot loss vs step\n", "plt.figure(figsize=(4.5,3))\n", "plt.plot(losses, label='train loss')\n", "plt.xlabel('step')\n", "plt.ylabel('MSE')\n", "plt.title('Linear regression: loss vs. step')\n", "plt.legend(); plt.tight_layout()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Linear Regression (End\u2011to\u2011End Example)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def linreg_demo(epochs: int = 400, lr: float = 3e-2):\n", "    g_cpu = torch.Generator().manual_seed(42)\n", "    w_true = torch.tensor([2.0, -3.5], device=device)\n", "    b_true = torch.tensor(0.5, device=device)\n", "    X = torch.randn(128, 2, generator=g_cpu).to(device)\n", "    y = (X @ w_true) + b_true + 0.1 * torch.randn(128, generator=g_cpu).to(device)\n", "    model = torch.nn.Linear(2, 1).to(device)\n", "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n", "    loss_fn = torch.nn.MSELoss()\n", "    for step in range(epochs + 1):\n", "        opt.zero_grad()\n", "        pred = model(X).squeeze(-1)\n", "        loss = loss_fn(pred, y)\n", "        loss.backward()\n", "        opt.step()\n", "        if step % 100 == 0:\n", "            print(step, round(loss.item(), 4))\n", "    return model.weight.detach().squeeze(0), model.bias.detach().squeeze(0)\n", "\n", "w, b = linreg_demo()\n", "w.cpu().tolist(), float(b)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}