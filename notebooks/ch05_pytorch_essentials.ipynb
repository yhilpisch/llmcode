{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925c6d5a",
   "metadata": {},
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=35% align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2707598",
   "metadata": {},
   "source": [
    "# Building a Large Language Model from Scratch — A Step-by-Step Guide Using Python and PyTorch\n",
    "## Chapter 5 — PyTorch Essentials\n",
    "**© Dr. Yves J. Hilpisch**<br>AI-Powered by GPT-5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f424a",
   "metadata": {},
   "source": [
    "## How to Use This Notebook\n",
    "\n",
    "- Rehearse core tensor manipulations you will reuse in every subsequent notebook.\n",
    "- Probe autograd with small, interpretable examples before scaling up.\n",
    "- Experiment with optimizers and schedulers on toy problems to gauge their behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0258f",
   "metadata": {},
   "source": [
    "### Roadmap\n",
    "\n",
    "We begin with tensors and broadcasting, explore gradients and computational graphs, and wrap up with a compact training loop that mirrors the full attoLLM pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f913516",
   "metadata": {},
   "source": [
    "### Study Tips\n",
    "\n",
    "Annotate the outputs of each section. Understanding *why* gradients or shapes look the way they do now will save hours when debugging the real model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44523b",
   "metadata": {
    "tags": [
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "# Install PyTorch in Colab or when torch is missing.\n",
    "try:\n",
    "    import torch  # noqa:F401\n",
    "    print('torch:', torch.__version__)\n",
    "except Exception:\n",
    "    import os\n",
    "    gpu = os.system('nvidia-smi > /dev/null 2>&1') == 0\n",
    "    index = 'https://download.pytorch.org/whl/cu121' if gpu else 'https://download.pytorch.org/whl/cpu'\n",
    "    get_ipython().run_line_magic('pip', f'install -q torch --index-url {index}')\n",
    "    import torch\n",
    "    print('torch:', torch.__version__, 'cuda?', torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick device\n",
    "import torch\n",
    "def pick_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    mps = getattr(torch.backends, 'mps', None)\n",
    "    if mps and torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    return torch.device('cpu')\n",
    "device = pick_device()\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d73cd3",
   "metadata": {},
   "source": [
    "## Tensors and Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "y = torch.ones_like(x)\n",
    "x.shape, y.shape, x.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([10.0, 20.0, 30.0])\n",
    "(x + b).shape, (x + b)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbc387",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)\n",
    "x.device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b0eed",
   "metadata": {},
   "source": [
    "## Autograd in a Nutshell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([2.0, -3.0, 0.5], requires_grad=True)\n",
    "v = torch.tensor([1.0, 2.0, 3.0])\n",
    "loss = (w * v).sum()\n",
    "loss.backward()\n",
    "w.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01160cb",
   "metadata": {},
   "source": [
    "## Optimizers and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(3, 1).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-3)\n",
    "crit = torch.nn.MSELoss()\n",
    "type(model), type(opt), type(crit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760045ea",
   "metadata": {},
   "source": [
    "## Training Loop Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8901ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU generator for determinism\n",
    "g_cpu = torch.Generator().manual_seed(0)\n",
    "g_cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs X\n",
    "X = torch.randn(64, 3, generator=g_cpu).to(device)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground-truth weights\n",
    "true_w = torch.tensor([1.0, -2.0, 0.5], device=device)\n",
    "true_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c327207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets with a touch of noise\n",
    "y = (X @ true_w) + 0.1 * torch.randn(64, generator=g_cpu).to(device)\n",
    "y[:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc641601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, optimizer, loss\n",
    "model = torch.nn.Linear(3, 1).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(model.parameters(), lr=5e-3)\n",
    "opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77bdf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "loss_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7617d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "losses = []\n",
    "for step in range(201):\n",
    "    opt.zero_grad()\n",
    "    pred = model(X).squeeze(-1)\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    losses.append(loss.detach().item())\n",
    "    if step % 50 == 0:\n",
    "        print(step, round(losses[-1], 4))\n",
    "losses[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1858faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "# Plot loss vs step\n",
    "plt.figure(figsize=(4.5,3))\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Linear regression: loss vs. step')\n",
    "plt.legend(); plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b2f79",
   "metadata": {},
   "source": [
    "## Linear Regression (End‑to‑End Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_demo(epochs: int = 400, lr: float = 3e-2):\n",
    "    g_cpu = torch.Generator().manual_seed(42)\n",
    "    w_true = torch.tensor([2.0, -3.5], device=device)\n",
    "    b_true = torch.tensor(0.5, device=device)\n",
    "    X = torch.randn(128, 2, generator=g_cpu).to(device)\n",
    "    y = (X @ w_true) + b_true + 0.1 * torch.randn(128, generator=g_cpu).to(device)\n",
    "    model = torch.nn.Linear(2, 1).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    for step in range(epochs + 1):\n",
    "        opt.zero_grad()\n",
    "        pred = model(X).squeeze(-1)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if step % 100 == 0:\n",
    "            print(step, round(loss.item(), 4))\n",
    "    return model.weight.detach().squeeze(0), model.bias.detach().squeeze(0)\n",
    "\n",
    "w, b = linreg_demo()\n",
    "w.cpu().tolist(), float(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86164087",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "- Rewrite the mini training loop to use the functional optimizers in `torch.optim.lr_scheduler`.\n",
    "- Implement gradient clipping and observe how it affects convergence on the toy dataset.\n",
    "- Create a unit test that checks whether your custom tensor operation preserves shape invariants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f029b",
   "metadata": {},
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=35% align=right>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
