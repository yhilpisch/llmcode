{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ba842e",
   "metadata": {},
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=35% align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb2714",
   "metadata": {},
   "source": [
    "# Building a Large Language Model from Scratch \u2014 A Step-by-Step Guide Using Python and PyTorch\n",
    "## Chapter 8 \u2014 The Transformer Architecture\n",
    "**\u00a9 Dr. Yves J. Hilpisch**<br>AI-Powered by GPT-5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ef853",
   "metadata": {},
   "source": [
    "## How to Use This Notebook\n",
    "\n",
    "- Assemble encoder and decoder blocks from reusable attention and feed-forward components.\n",
    "- Trace tensor shapes through the model to prevent broadcasting surprises.\n",
    "- Benchmark a forward pass to sanity-check performance before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867efadf",
   "metadata": {},
   "source": [
    "### Roadmap\n",
    "\n",
    "You will wire positional encodings, stack attention blocks, and integrate residual connections to form a minimal transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04be8a",
   "metadata": {},
   "source": [
    "### Study Tips\n",
    "\n",
    "Keep a diagram of the architecture nearby. Annotating where tensors enter and exit each sublayer makes debugging much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure torch (Colab friendly)\n",
    "try:\n",
    "    import torch  # noqa\n",
    "    print('torch:', torch.__version__)\n",
    "except Exception:\n",
    "    import os\n",
    "    gpu = os.system('nvidia-smi > /dev/null 2>&1') == 0\n",
    "    index = (\n",
    "        'https://download.pytorch.org/whl/cu121'\n",
    "        if gpu else 'https://download.pytorch.org/whl/cpu'\n",
    "    )\n",
    "    get_ipython().run_line_magic('pip', f'install -q torch --index-url {index}')\n",
    "    import torch\n",
    "    print('torch:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b51069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%config InlineBackend.figure_format = 'svg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf85d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional encoding\n",
    "def sinusoidal_positions(T: int, d_model: int, device=None):\n",
    "    import math, torch\n",
    "    pos = torch.arange(T, device=device).float()[:, None]\n",
    "    i = torch.arange(d_model, device=device).float()[None, :]\n",
    "    angle = pos / (10000 ** (2 * (i // 2) / d_model))\n",
    "    enc = torch.zeros(T, d_model, device=device)\n",
    "    enc[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "    enc[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "    return enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-head attention\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, dropout: float = 0.0):\n",
    "        super().__init__(); assert d_model % num_heads == 0\n",
    "        self.h = num_heads; self.d = d_model // num_heads\n",
    "        self.qkv = nn.Linear(d_model, 3*d_model, bias=False)\n",
    "        self.out = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    def forward(self, x, mask=None):\n",
    "        B, T, Dm = x.shape\n",
    "        qkv = self.qkv(x); q, k, v = qkv.chunk(3, dim=-1)\n",
    "        def split(t): return t.view(B, T, self.h, self.d).transpose(1, 2)\n",
    "        q, k, v = map(split, (q, k, v))\n",
    "        attn = F.scaled_dot_product_attention(q, k, v, attn_mask=mask)\n",
    "        attn = self.drop(attn)\n",
    "        y = attn.transpose(1,2).contiguous().view(B, T, Dm)\n",
    "        return self.out(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f803a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check head shapes in isolation\n",
    "B, T, D, H = 2, 5, 12, 3\n",
    "x_chk = torch.randn(B, T, D)\n",
    "mha_chk = MultiHeadAttention(D, H)\n",
    "qkv = mha_chk.qkv(x_chk); q, k, v = qkv.chunk(3, dim=-1)\n",
    "def split(t): return t.view(B, T, H, D//H).transpose(1, 2)\n",
    "qh, kh, vh = map(split, (q, k, v))\n",
    "q.shape, qh.shape, (H * (D//H)) == D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f5a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual + LayerNorm (pre-norm)\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__(); self.norm = nn.LayerNorm(d_model)\n",
    "    def forward(self, x, sublayer, *args, **kwargs):\n",
    "        return x + sublayer(self.norm(x), *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232fee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed-forward\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.0):\n",
    "        super().__init__(); self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model), nn.Dropout(dropout))\n",
    "    def forward(self, x): return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ee32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "        self.res1 = Residual(d_model); self.res2 = Residual(d_model)\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.res1(x, self.mha, mask)\n",
    "        x = self.res2(x, self.ffn)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create toy input\n",
    "B, T, D = 2, 6, 16\n",
    "x = torch.randn(B, T, D)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63880883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sinusoidal positions\n",
    "pe = sinusoidal_positions(T, D)\n",
    "pe.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x + pe[None, :, :]\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4122893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causal mask\n",
    "mask = torch.tril(torch.ones(T, T))[None, :, :]\n",
    "mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block and forward\n",
    "block = TransformerBlock(D, num_heads=4, d_ff=64, dropout=0.1)\n",
    "block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3742ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = block(x, mask)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ebd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention weights of a single head from the block\n",
    "with torch.no_grad():\n",
    "    B, T, Dm = x.shape\n",
    "    # re-compute q,k for visualization\n",
    "    qkv = block.mha.qkv(x); q, k, v = qkv.chunk(3, dim=-1)\n",
    "    H = block.mha.h; Dh = block.mha.d\n",
    "    def split(t): return t.view(B, T, H, Dh).transpose(1, 2)\n",
    "    qh, kh = map(split, (q, k))\n",
    "    d = Dh\n",
    "    scores = (qh @ kh.transpose(-2, -1)) / (d ** 0.5)  # [B,H,T,T]\n",
    "    scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    w = torch.softmax(scores, dim=-1)[0, 0]  # head 0 weights [T,T]\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.imshow(w, cmap='magma', aspect='auto')\n",
    "plt.colorbar(label='weight')\n",
    "plt.xlabel('key\\npositions')\n",
    "plt.ylabel('query positions')\n",
    "plt.title('Head 0 weights (toy)')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d59979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second block for a quick stability check\n",
    "block2 = TransformerBlock(D, num_heads=4, d_ff=64, dropout=0.1)\n",
    "block2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2252b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure mean/std before and after each block\n",
    "with torch.no_grad():\n",
    "    def stats(t): return float(t.mean()), float(t.std())\n",
    "    m0, s0 = stats(x)\n",
    "    y1 = block(x, mask)\n",
    "    m1, s1 = stats(y1)\n",
    "    y2 = block2(y1, mask)\n",
    "    m2, s2 = stats(y2)\n",
    "    print('(mean,std) before:', (round(m0,4), round(s0,4)))\n",
    "    print('after block 1   :', (round(m1,4), round(s1,4)))\n",
    "    print('after block 2   :', (round(m2,4), round(s2,4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5081e2",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "- Swap the sinusoidal positional encoding for a learned variant and observe the impact.\n",
    "- Instrument the model with hooks to capture intermediate activations for later analysis.\n",
    "- Profile the forward pass with different sequence lengths to understand scaling behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b521d47",
   "metadata": {},
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=35% align=right>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}